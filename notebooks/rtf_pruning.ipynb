{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-19T07:29:53.898123Z",
     "start_time": "2024-12-19T07:29:53.876602Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import src.data_processing as dp\n",
    "from src.rtf_pruning import prune_attention_heads,prune_heads_and_shrink,model_heads_by_magnitude\n",
    "from sdmetrics.reports.single_table import QualityReport\n",
    "from sdmetrics.reports.single_table import DiagnosticReport\n",
    "from realtabformer import REaLTabFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_data, test_data, sample_data = dp.csv_data_split(\"../data/breast-cancer-wisconsin.csv\")\n",
    "my_metadata_dict = dp.metadata(\"../data/cancer_metadata.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T07:29:54.732688Z",
     "start_time": "2024-12-19T07:29:54.673428Z"
    }
   },
   "id": "5adc58787ee41f20"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "rtf_model = REaLTabFormer.load_from_dir(\"../models/rtf_regular/id000017342890144858071040\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T18:42:33.104197Z",
     "start_time": "2024-12-19T18:42:31.857589Z"
    }
   },
   "id": "7c60d7c7d4d8332f"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "heads_to_prune = model_heads_by_magnitude(model=rtf_model.model,percentage=0.3,num_heads_per_layer=12,layers=6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T18:33:37.426307Z",
     "start_time": "2024-12-19T18:33:37.400635Z"
    }
   },
   "id": "5345f8a43349b66f"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0, [8, 2, 1, 7]),\n (1, [2, 11, 0, 7]),\n (2, [5, 6, 8, 0]),\n (3, [5, 2, 10, 9]),\n (4, [8, 2, 3, 6]),\n (5, [6, 4, 5, 0])]"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heads_to_prune"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T18:33:38.038144Z",
     "start_time": "2024-12-19T18:33:38.007406Z"
    }
   },
   "id": "b5f409bd90bf50d2"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing transformer.h.0.attn.c_attn\n",
      "Processing transformer.h.0.attn.c_proj\n",
      "Processing transformer.h.0.mlp.c_fc\n",
      "Processing transformer.h.0.mlp.c_proj\n",
      "Processing transformer.h.1.attn.c_attn\n",
      "Processing transformer.h.1.attn.c_proj\n",
      "Processing transformer.h.1.mlp.c_fc\n",
      "Processing transformer.h.1.mlp.c_proj\n",
      "Processing transformer.h.2.attn.c_attn\n",
      "Processing transformer.h.2.attn.c_proj\n",
      "Processing transformer.h.2.mlp.c_fc\n",
      "Processing transformer.h.2.mlp.c_proj\n",
      "Processing transformer.h.3.attn.c_attn\n",
      "Processing transformer.h.3.attn.c_proj\n",
      "Processing transformer.h.3.mlp.c_fc\n",
      "Processing transformer.h.3.mlp.c_proj\n",
      "Processing transformer.h.4.attn.c_attn\n",
      "Processing transformer.h.4.attn.c_proj\n",
      "Processing transformer.h.4.mlp.c_fc\n",
      "Processing transformer.h.4.mlp.c_proj\n",
      "Processing transformer.h.5.attn.c_attn\n",
      "Processing transformer.h.5.attn.c_proj\n",
      "Processing transformer.h.5.mlp.c_fc\n",
      "Processing transformer.h.5.mlp.c_proj\n"
     ]
    }
   ],
   "source": [
    "prune_attention_heads(rtf_model.model,heads_to_prune)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T18:41:37.543655Z",
     "start_time": "2024-12-19T18:41:37.229454Z"
    }
   },
   "id": "b6be1d08fd92407d"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 has 8 attention heads.\n",
      "Layer 1 has 8 attention heads.\n",
      "Layer 2 has 8 attention heads.\n",
      "Layer 3 has 8 attention heads.\n",
      "Layer 4 has 8 attention heads.\n",
      "Layer 5 has 8 attention heads.\n"
     ]
    }
   ],
   "source": [
    "for i, block in enumerate(rtf_model.model.transformer.h):\n",
    "    num_heads = block.attn.num_heads\n",
    "    print(f\"Layer {i} has {num_heads} attention heads.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T18:34:00.539440Z",
     "start_time": "2024-12-19T18:34:00.520313Z"
    }
   },
   "id": "204809056447f59"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/PycharmProjects/model-compression/venv/lib/python3.11/site-packages/realtabformer/realtabformer.py:77: UserWarning: The device=cuda is not available, using device=cpu instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/137 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac446624ecbe46d38932bc886e1f0c50"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 256 samples generated. Sampling efficiency is: 100.0000%\n",
      "             Property     Score\n",
      "0       Column Shapes  0.921168\n",
      "1  Column Pair Trends  0.913513\n",
      "         Property     Score\n",
      "0   Data Validity  0.994691\n",
      "1  Data Structure  1.000000\n"
     ]
    }
   ],
   "source": [
    "synthetic_data2 = rtf_model.sample(n_samples=len(test_data))\n",
    "\n",
    "quality = QualityReport()\n",
    "diagnostic = DiagnosticReport()\n",
    "\n",
    "quality.generate(test_data,synthetic_data2,metadata=my_metadata_dict,verbose=False)\n",
    "diagnostic.generate(test_data,synthetic_data2,metadata=my_metadata_dict,verbose=False)\n",
    "\n",
    "print(quality.get_properties())\n",
    "print(diagnostic.get_properties())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T18:42:56.617512Z",
     "start_time": "2024-12-19T18:42:47.183716Z"
    }
   },
   "id": "25f918893e032fc5"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 has 6 attention heads.\n",
      "Layer 1 has 6 attention heads.\n",
      "Layer 2 has 6 attention heads.\n",
      "Layer 3 has 6 attention heads.\n"
     ]
    }
   ],
   "source": [
    "for i, block in enumerate(rtf_model.model.transformer.h):\n",
    "    num_heads = block.attn.num_heads\n",
    "    print(f\"Layer {i} has {num_heads} attention heads.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T16:44:34.716916Z",
     "start_time": "2024-12-19T16:44:34.695787Z"
    }
   },
   "id": "810d74aa2e7e2423"
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning layer: transformer.h.0.attn.c_attn\n",
      "Pruning layer: transformer.h.0.attn.c_proj\n",
      "Pruning layer: transformer.h.0.mlp.c_fc\n",
      "Pruning layer: transformer.h.0.mlp.c_proj\n",
      "Pruning layer: transformer.h.1.attn.c_attn\n",
      "Pruning layer: transformer.h.1.attn.c_proj\n",
      "Pruning layer: transformer.h.1.mlp.c_fc\n",
      "Pruning layer: transformer.h.1.mlp.c_proj\n",
      "Pruning layer: transformer.h.2.attn.c_attn\n",
      "Pruning layer: transformer.h.2.attn.c_proj\n",
      "Pruning layer: transformer.h.2.mlp.c_fc\n",
      "Pruning layer: transformer.h.2.mlp.c_proj\n",
      "Pruning layer: transformer.h.3.attn.c_attn\n",
      "Pruning layer: transformer.h.3.attn.c_proj\n",
      "Pruning layer: transformer.h.3.mlp.c_fc\n",
      "Pruning layer: transformer.h.3.mlp.c_proj\n"
     ]
    }
   ],
   "source": [
    "# indices = torch.LongTensor([i for i in range(0, 512, 2 )])  # Keep 100 out of 512 channels\n",
    "apply_structured_pruning(rtf_model.model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T00:26:47.186011Z",
     "start_time": "2024-12-19T00:26:47.039892Z"
    }
   },
   "id": "cc6785d8da856e47"
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.00%\n",
      "Total: 12164608\n",
      "Zero: 0\n"
     ]
    }
   ],
   "source": [
    "def compute_sparsity(model):\n",
    "    total_params = 0\n",
    "    zero_params = 0\n",
    "    for param in model.parameters():\n",
    "        total_params += param.numel()\n",
    "        zero_params += (param == 0).sum().item()\n",
    "    \n",
    "    sparsity = zero_params / total_params\n",
    "    return sparsity,total_params, zero_params\n",
    "\n",
    "# Example usage\n",
    "sparsity, total_params, zero_params = compute_sparsity(rtf_model.model)\n",
    "print(f\"Sparsity: {sparsity * 100:.2f}%\")\n",
    "print(f\"Total: {total_params}\")\n",
    "print(f\"Zero: {zero_params}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T06:19:48.542774Z",
     "start_time": "2024-12-19T06:19:48.470311Z"
    }
   },
   "id": "60906374c2fd3d36"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 154847232 bytes\n"
     ]
    }
   ],
   "source": [
    "def model_size(model):\n",
    "    return sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "\n",
    "print(f\"Model size: {model_size(rtf_model.model)} bytes\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T18:34:06.526878Z",
     "start_time": "2024-12-19T18:34:06.509967Z"
    }
   },
   "id": "bee0f21dd6822334"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 154847232 bytes\n"
     ]
    }
   ],
   "source": [
    "def model_size(model):\n",
    "    return sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "\n",
    "print(f\"Model size: {model_size(rtf_model.model)} bytes\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T18:36:42.603777Z",
     "start_time": "2024-12-19T18:36:42.583247Z"
    }
   },
   "id": "cfdcf41e76fd3d37"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9205346764819837"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "48658432/52858880"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T16:46:57.020830Z",
     "start_time": "2024-12-19T16:46:57.000395Z"
    }
   },
   "id": "4cf346ef81ba1934"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/PycharmProjects/model-compression/venv/lib/python3.11/site-packages/realtabformer/realtabformer.py:77: UserWarning: The device=cuda is not available, using device=cpu instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/137 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a36006752c334010894988a3192b840b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 256 samples generated. Sampling efficiency is: 100.0000%\n",
      "             Property     Score\n",
      "0       Column Shapes  0.869343\n",
      "1  Column Pair Trends  0.874957\n",
      "         Property     Score\n",
      "0   Data Validity  0.998009\n",
      "1  Data Structure  1.000000\n"
     ]
    }
   ],
   "source": [
    "synthetic_data = rtf_model.sample(n_samples=(len(test_data)))\n",
    "\n",
    "quality = QualityReport()\n",
    "diagnostic = DiagnosticReport()\n",
    "\n",
    "quality.generate(test_data,synthetic_data,metadata=my_metadata_dict,verbose=False)\n",
    "diagnostic.generate(test_data,synthetic_data,metadata=my_metadata_dict,verbose=False)\n",
    "\n",
    "print(quality.get_properties())\n",
    "print(diagnostic.get_properties())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T18:42:23.508467Z",
     "start_time": "2024-12-19T18:42:15.566315Z"
    }
   },
   "id": "753e360eb493f43"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This directory is not empty, and contains either a config or a model. Consider setting `allow_overwrite=True` if you want to overwrite these.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[80], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mrtf_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msave/\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/model-compression/venv/lib/python3.11/site-packages/realtabformer/realtabformer.py:1409\u001B[0m, in \u001B[0;36mREaLTabFormer.save\u001B[0;34m(self, path, allow_overwrite)\u001B[0m\n\u001B[1;32m   1407\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m path\u001B[38;5;241m.\u001B[39mis_dir() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_overwrite:\n\u001B[1;32m   1408\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config_file\u001B[38;5;241m.\u001B[39mexists() \u001B[38;5;129;01mor\u001B[39;00m model_file\u001B[38;5;241m.\u001B[39mexists():\n\u001B[0;32m-> 1409\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1410\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis directory is not empty, and contains either a config or a model.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1411\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Consider setting `allow_overwrite=True` if you want to overwrite these.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1412\u001B[0m         )\n\u001B[1;32m   1413\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1414\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1415\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDirectory \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m exists, but `allow_overwrite=False`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1416\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m This will raise an error next time when the model artifacts \u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[1;32m   1417\u001B[0m \u001B[38;5;124m                exist on this directory\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1418\u001B[0m         )\n",
      "\u001B[0;31mValueError\u001B[0m: This directory is not empty, and contains either a config or a model. Consider setting `allow_overwrite=True` if you want to overwrite these."
     ]
    }
   ],
   "source": [
    "rtf_model.save(\"save/\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T18:42:03.238046Z",
     "start_time": "2024-12-19T18:42:03.222552Z"
    }
   },
   "id": "aeb9096c4fc1526a"
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GPT2LMHeadModel:\n\tsize mismatch for transformer.wte.weight: copying a param with shape torch.Size([156, 512]) from checkpoint, the shape in current model is torch.Size([156, 256]).\n\tsize mismatch for transformer.wpe.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for transformer.h.0.ln_1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.0.ln_1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.0.ln_2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.0.ln_2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.1.ln_1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.1.ln_1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.1.ln_2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.1.ln_2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.2.ln_1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.2.ln_1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.2.ln_2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.2.ln_2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.3.ln_1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.3.ln_1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.3.ln_2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.3.ln_2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.ln_f.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.ln_f.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([156, 512]) from checkpoint, the shape in current model is torch.Size([156, 256]).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[134], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m test \u001B[38;5;241m=\u001B[39m \u001B[43mREaLTabFormer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_from_dir\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/Users/sebastian/PycharmProjects/model-compression/notebooks/testing/id000017342868701547638784\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/model-compression/venv/lib/python3.11/site-packages/realtabformer/realtabformer.py:1572\u001B[0m, in \u001B[0;36mREaLTabFormer.load_from_dir\u001B[0;34m(cls, path)\u001B[0m\n\u001B[1;32m   1569\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1570\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid model_type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrealtf\u001B[38;5;241m.\u001B[39mmodel_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1572\u001B[0m \u001B[43mrealtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_state_dict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1573\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_file\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_posix\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m   1574\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1576\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m realtf\n",
      "File \u001B[0;32m~/PycharmProjects/model-compression/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:2153\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[0;34m(self, state_dict, strict, assign)\u001B[0m\n\u001B[1;32m   2148\u001B[0m         error_msgs\u001B[38;5;241m.\u001B[39minsert(\n\u001B[1;32m   2149\u001B[0m             \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing key(s) in state_dict: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   2150\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m missing_keys)))\n\u001B[1;32m   2152\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(error_msgs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 2153\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mError(s) in loading state_dict for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   2154\u001B[0m                        \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(error_msgs)))\n\u001B[1;32m   2155\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for GPT2LMHeadModel:\n\tsize mismatch for transformer.wte.weight: copying a param with shape torch.Size([156, 512]) from checkpoint, the shape in current model is torch.Size([156, 256]).\n\tsize mismatch for transformer.wpe.weight: copying a param with shape torch.Size([1024, 512]) from checkpoint, the shape in current model is torch.Size([1024, 256]).\n\tsize mismatch for transformer.h.0.ln_1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.0.ln_1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.0.ln_2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.0.ln_2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.1.ln_1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.1.ln_1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.1.ln_2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.1.ln_2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.2.ln_1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.2.ln_1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.2.ln_2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.2.ln_2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.3.ln_1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.3.ln_1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.3.ln_2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.h.3.ln_2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.ln_f.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for transformer.ln_f.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([156, 512]) from checkpoint, the shape in current model is torch.Size([156, 256])."
     ]
    }
   ],
   "source": [
    "test = REaLTabFormer.load_from_dir(\"/Users/sebastian/PycharmProjects/model-compression/notebooks/testing/id000017342868701547638784\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T19:29:20.645195Z",
     "start_time": "2024-12-18T19:29:20.346292Z"
    }
   },
   "id": "2d661bba7696f87d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "synthetic_data_pruned = 0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "583e66cf5ad8024c"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from sdmetrics.single_table import BinaryDecisionTreeClassifier\n",
    "\n",
    "def evaluate_model(test_data, synthetic_data, target, metadata):\n",
    "    return BinaryDecisionTreeClassifier.compute(\n",
    "        test_data=test_data,\n",
    "        train_data=synthetic_data,\n",
    "        target=target,\n",
    "        metadata=metadata\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T16:57:00.700987Z",
     "start_time": "2024-12-19T16:57:00.680482Z"
    }
   },
   "id": "11e6dee78bbeadab"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8461538461538461"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(test_data,synthetic_data_pruned,'Class',my_metadata_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T16:59:48.133589Z",
     "start_time": "2024-12-19T16:59:48.097999Z"
    }
   },
   "id": "7e7a19fad16ec51c"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8712871287128713"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(test_data,synthetic_data,'Class',my_metadata_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T16:59:55.849035Z",
     "start_time": "2024-12-19T16:59:55.811068Z"
    }
   },
   "id": "64f6fdc1fe19f3e1"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/sebastian/PycharmProjects/model-compression/notebooks/testing/id000017342868701547638784/rtf_model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m checkpoint \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/Users/sebastian/PycharmProjects/model-compression/notebooks/testing/id000017342868701547638784/rtf_model.pt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m checkpoint\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mis_tensor(value):\n",
      "File \u001B[0;32m~/PycharmProjects/model-compression/venv/lib/python3.11/site-packages/torch/serialization.py:998\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[1;32m    995\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    996\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 998\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[1;32m    999\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[1;32m   1000\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[1;32m   1001\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[1;32m   1002\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[1;32m   1003\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[0;32m~/PycharmProjects/model-compression/venv/lib/python3.11/site-packages/torch/serialization.py:445\u001B[0m, in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[1;32m    444\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[0;32m--> 445\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    446\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    447\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[0;32m~/PycharmProjects/model-compression/venv/lib/python3.11/site-packages/torch/serialization.py:426\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    425\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[0;32m--> 426\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Users/sebastian/PycharmProjects/model-compression/notebooks/testing/id000017342868701547638784/rtf_model.pt'"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"/Users/sebastian/PycharmProjects/model-compression/notebooks/testing/id000017342868701547638784/rtf_model.pt\")\n",
    "for key, value in checkpoint.items():\n",
    "    if torch.is_tensor(value):\n",
    "        print(f\"Key: {key}, Shape: {value.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-19T16:59:25.946375Z",
     "start_time": "2024-12-19T16:59:25.136911Z"
    }
   },
   "id": "bdf75ce6d1a95bfc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "64ff00cbdabaaeb3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
