{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-18T18:18:43.432787Z",
     "start_time": "2024-12-18T18:18:30.696938Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers.pytorch_utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import prune\n",
    "import transformers.pytorch_utils\n",
    "import src.data_processing as dp\n",
    "from sdmetrics.reports.single_table import QualityReport\n",
    "from sdmetrics.reports.single_table import DiagnosticReport\n",
    "from realtabformer import REaLTabFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "          ID  CT  UCSi  UCSh  Madh  SECS  BN  BC  NN  Mi  Class\n175  1001010   1     1     1     1     0   1   1   1   1      0\n162  1198611   3     1     1     1     0   1   3   1   1      0\n356   190561   1     3     0     1     3   1   0   1   1      0\n488  1065899   1     1     1     1     0   1   3   1   1      0\n409  1057938   3     1     1     1     0   1   1   1   1      0\n..       ...  ..   ...   ...   ...   ...  ..  ..  ..  ..    ...\n181  1006811  10     5     6    10     6  10   7   7  10      1\n448  1080058   1     1     1     1     0   1   1   0   1      0\n112  1173035   3     3     0     1     0   3   3   1   1      0\n557   183936   3     1     1     1     0   1   0   1   1      0\n58   1115080   5     3     5     5     3   3   1  10   1      1\n\n[137 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>CT</th>\n      <th>UCSi</th>\n      <th>UCSh</th>\n      <th>Madh</th>\n      <th>SECS</th>\n      <th>BN</th>\n      <th>BC</th>\n      <th>NN</th>\n      <th>Mi</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>175</th>\n      <td>1001010</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>1198611</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>356</th>\n      <td>190561</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>1065899</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>409</th>\n      <td>1057938</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>1006811</td>\n      <td>10</td>\n      <td>5</td>\n      <td>6</td>\n      <td>10</td>\n      <td>6</td>\n      <td>10</td>\n      <td>7</td>\n      <td>7</td>\n      <td>10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>448</th>\n      <td>1080058</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>1173035</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>557</th>\n      <td>183936</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>1115080</td>\n      <td>5</td>\n      <td>3</td>\n      <td>5</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>137 rows Ã— 11 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data, sample_data = dp.csv_data_split(\"../data/breast-cancer-wisconsin.csv\")\n",
    "my_metadata_dict = dp.metadata(\"../data/cancer_metadata.json\")\n",
    "test_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T18:18:43.521568Z",
     "start_time": "2024-12-18T18:18:43.443460Z"
    }
   },
   "id": "c2be796ff8fab988"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model = REaLTabFormer.load_from_dir(\"../models/rtf_small/id000017342868701547638784\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T18:19:35.557555Z",
     "start_time": "2024-12-18T18:19:34.980551Z"
    }
   },
   "id": "7195c1b95d6331d3"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/PycharmProjects/model-compression/venv/lib/python3.11/site-packages/realtabformer/realtabformer.py:77: UserWarning: The device=cuda is not available, using device=cpu instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/137 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74ec429412ed45fcba22b9f871a1704f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 invalid samples out of total 256 samples generated. Sampling efficiency is: 100.0000%\n"
     ]
    }
   ],
   "source": [
    "synthetic_data = model.sample(n_samples=len(test_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T18:19:44.977668Z",
     "start_time": "2024-12-18T18:19:37.341170Z"
    }
   },
   "id": "d94259ded72a67cf"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "             Property     Score\n0       Column Shapes  0.489051\n1  Column Pair Trends  0.606610",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Property</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Column Shapes</td>\n      <td>0.489051</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Column Pair Trends</td>\n      <td>0.606610</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality = QualityReport()\n",
    "quality.generate(test_data,synthetic_data,my_metadata_dict,verbose=False)\n",
    "quality.get_properties()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T18:19:45.622856Z",
     "start_time": "2024-12-18T18:19:44.973248Z"
    }
   },
   "id": "bf77f9297b8d5ca9"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "         Property     Score\n0   Data Validity  0.935634\n1  Data Structure  1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Property</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Data Validity</td>\n      <td>0.935634</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Data Structure</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnostic = DiagnosticReport()\n",
    "diagnostic.generate(test_data,synthetic_data,my_metadata_dict,verbose=False)\n",
    "diagnostic.get_properties()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T18:19:45.748583Z",
     "start_time": "2024-12-18T18:19:45.633172Z"
    }
   },
   "id": "68c5912caac7d3c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    \"small_model\": \"../models/rtf_small/id000017342868701547638784\",\n",
    "    \"regular_model\": \"../models/rtf_regular/id000017342890144858071040\",\n",
    "    # \"large_model\": \"../models/rtf_large/id000017341472610579369984\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "490b08f4fffcffba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = []"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae86cedafc67cbdd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_generations = 5\n",
    "\n",
    "# Loop through different models\n",
    "for model_name, model_path in models_dict.items():\n",
    "    # Load the model\n",
    "    model = REaLTabFormer.load_from_dir(model_path)\n",
    "    \n",
    "    # Initialize accumulators for scores\n",
    "    column_shapes_scores = []\n",
    "    column_pair_trends_scores = []\n",
    "    data_validity_scores = []\n",
    "    data_structure_scores = []\n",
    "    \n",
    "    # Generate multiple synthetic datasets and compute scores\n",
    "    for _ in range(n_generations):\n",
    "        synthetic_data = model.sample(n_samples=len(test_data))\n",
    "        \n",
    "        # Generate quality and diagnostic reports\n",
    "        quality = QualityReport()\n",
    "        quality.generate(test_data, synthetic_data, my_metadata_dict, verbose=False)\n",
    "        diagnostic = DiagnosticReport()\n",
    "        diagnostic.generate(test_data, synthetic_data, my_metadata_dict, verbose=False)\n",
    "        \n",
    "        # Extract individual scores\n",
    "        column_shapes = quality.get_properties().loc[\n",
    "            quality.get_properties()['Property'] == 'Column Shapes', 'Score'\n",
    "        ].values[0]\n",
    "        column_pair_trends = quality.get_properties().loc[\n",
    "            quality.get_properties()['Property'] == 'Column Pair Trends', 'Score'\n",
    "        ].values[0]\n",
    "        data_validity = diagnostic.get_properties().loc[\n",
    "            diagnostic.get_properties()['Property'] == 'Data Validity', 'Score'\n",
    "        ].values[0]\n",
    "        data_structure = diagnostic.get_properties().loc[\n",
    "            diagnostic.get_properties()['Property'] == 'Data Structure', 'Score'\n",
    "        ].values[0]\n",
    "        \n",
    "        # Append scores to accumulators\n",
    "        column_shapes_scores.append(column_shapes)\n",
    "        column_pair_trends_scores.append(column_pair_trends)\n",
    "        data_validity_scores.append(data_validity)\n",
    "        data_structure_scores.append(data_structure)\n",
    "    \n",
    "    # Calculate average scores\n",
    "    avg_column_shapes = sum(column_shapes_scores) / n_generations\n",
    "    avg_column_pair_trends = sum(column_pair_trends_scores) / n_generations\n",
    "    avg_data_validity = sum(data_validity_scores) / n_generations\n",
    "    avg_data_structure = sum(data_structure_scores) / n_generations\n",
    "    \n",
    "    # Calculate total score\n",
    "    avg_total_score = (\n",
    "        0.40 * avg_column_shapes +\n",
    "        0.40 * avg_column_pair_trends +\n",
    "        0.10 * avg_data_validity +\n",
    "        0.10 * avg_data_structure\n",
    "    )\n",
    "    \n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Avg Column Shapes\": avg_column_shapes,\n",
    "        \"Avg Column Pair Trends\": avg_column_pair_trends,\n",
    "        \"Avg Data Validity\": avg_data_validity,\n",
    "        \"Avg Data Structure\": avg_data_structure,\n",
    "        \"Avg Total Score\": avg_total_score\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7c9959e15f04ce0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp = train_data.head()\n",
    "temp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "647282c1dfab5e25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "    data=test_data.drop('Class', axis=1),\n",
    "    target_col='Class',\n",
    "    disable_progress_bar = True,\n",
    "    fillunk=False,\n",
    "    target_pos_val=1\n",
    ")\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "967ab7e3fa561e18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data['Class'].head(10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2275946c4a70e4d4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sdmetrics.single_table import BinaryDecisionTreeClassifier\n",
    "\n",
    "def load_and_generate_synthetic_data(model_dir, n_samples, metadata):\n",
    "    model = REaLTabFormer.load_from_dir(model_dir)\n",
    "    synthetic_data = model.sample(n_samples=n_samples)\n",
    "    return synthetic_data\n",
    "\n",
    "def evaluate_model(test_data, synthetic_data, target, metadata):\n",
    "    return BinaryDecisionTreeClassifier.compute(\n",
    "        test_data=test_data,\n",
    "        train_data=synthetic_data,\n",
    "        target=target,\n",
    "        metadata=metadata\n",
    "    )\n",
    "\n",
    "# Model directories\n",
    "model_dirs = [\n",
    "    \"../models/rtf_small/id000017342868701547638784\",\n",
    "    \"../models/rtf_regular/id000017342890144858071040\",\n",
    "    \"../models/rtf_large/id000017342929846661560320\"\n",
    "]\n",
    "\n",
    "# Number of runs\n",
    "n_runs = 5\n",
    "\n",
    "# Evaluate each model\n",
    "for model_dir in model_dirs:\n",
    "    scores = []\n",
    "    for _ in range(n_runs):\n",
    "        # Generate synthetic data\n",
    "        synthetic_data = load_and_generate_synthetic_data(model_dir, len(test_data), my_metadata_dict)\n",
    "        \n",
    "        # Evaluate the synthetic data\n",
    "        evaluation_score = evaluate_model(test_data, synthetic_data, target='Class', metadata=my_metadata_dict)\n",
    "        \n",
    "        # Append score to list\n",
    "        scores.append(evaluation_score)\n",
    "\n",
    "    # Compute average score\n",
    "    average_score = np.mean(scores)\n",
    "    print(f\"Average Evaluation for model {model_dir}: {average_score}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "831ae2fb5fc1e6d4"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def prune_conv1d_layer(layer,amount):\n",
    "    prune.ln_structured(layer, name='weight', amount=amount, dim=1,n=float('-inf'))\n",
    "    prune.remove(layer,name='weight')\n",
    "    \n",
    "def apply_structured_pruning(model,amount):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Module):\n",
    "            if isinstance(module, transformers.pytorch_utils.Conv1D):\n",
    "                prune_conv1d_layer(module,amount)\n",
    "                \n",
    "def print_tensor(model):\n",
    "    sparse_model = model\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.dim() == 2:\n",
    "            print(name,param.size())\n",
    "\n",
    "def convert_to_sparse(model):\n",
    "    test = model\n",
    "    for name, param in test.named_parameters():\n",
    "        if param.dim() == 2:  # Apply to weight matrices\n",
    "            # Convert to sparse tensor\n",
    "            param  = param.data.to_sparse()\n",
    "        \n",
    "    return test\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T18:24:25.355898Z",
     "start_time": "2024-12-18T18:24:25.327711Z"
    }
   },
   "id": "7861a9a6e790d0c9"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight torch.Size([156, 512])\n",
      "transformer.wpe.weight torch.Size([1024, 512])\n",
      "transformer.h.0.attn.c_attn.weight torch.Size([512, 1536])\n",
      "transformer.h.0.attn.c_proj.weight torch.Size([512, 512])\n",
      "transformer.h.0.mlp.c_fc.weight torch.Size([512, 2048])\n",
      "transformer.h.0.mlp.c_proj.weight torch.Size([2048, 512])\n",
      "transformer.h.1.attn.c_attn.weight torch.Size([512, 1536])\n",
      "transformer.h.1.attn.c_proj.weight torch.Size([512, 512])\n",
      "transformer.h.1.mlp.c_fc.weight torch.Size([512, 2048])\n",
      "transformer.h.1.mlp.c_proj.weight torch.Size([2048, 512])\n",
      "transformer.h.2.attn.c_attn.weight torch.Size([512, 1536])\n",
      "transformer.h.2.attn.c_proj.weight torch.Size([512, 512])\n",
      "transformer.h.2.mlp.c_fc.weight torch.Size([512, 2048])\n",
      "transformer.h.2.mlp.c_proj.weight torch.Size([2048, 512])\n",
      "transformer.h.3.attn.c_attn.weight torch.Size([512, 1536])\n",
      "transformer.h.3.attn.c_proj.weight torch.Size([512, 512])\n",
      "transformer.h.3.mlp.c_fc.weight torch.Size([512, 2048])\n",
      "transformer.h.3.mlp.c_proj.weight torch.Size([2048, 512])\n"
     ]
    }
   ],
   "source": [
    "print_tensor(model.model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T18:24:25.574760Z",
     "start_time": "2024-12-18T18:24:25.546721Z"
    }
   },
   "id": "7eba6c62e04d3087"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "model_file = convert_to_sparse(model.model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T18:22:42.722978Z",
     "start_time": "2024-12-18T18:22:42.385130Z"
    }
   },
   "id": "deb8b6e28c82c7a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for name, module in model.model.named_modules():        \n",
    "    if isinstance(module, transformers.pytorch_utils.Conv1D):\n",
    "            print(name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d67297ae05891bc2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_sparsity(model):\n",
    "    total_params = 0\n",
    "    zero_params = 0\n",
    "    for param in model.parameters():\n",
    "        total_params += param.numel()\n",
    "        zero_params += (param == 0).sum().item()\n",
    "    \n",
    "    sparsity = zero_params / total_params\n",
    "    return sparsity,total_params, zero_params\n",
    "\n",
    "# Example usage\n",
    "sparsity, total_params, zero_params = compute_sparsity(model.model)\n",
    "print(f\"Sparsity: {sparsity * 100:.2f}%\")\n",
    "print(f\"Total: {total_params}\")\n",
    "print(f\"Zero: {zero_params}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f002c9f686256399"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"../models/small/\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13c356210b8649f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.quantization import quantize_dynamic\n",
    "\n",
    "def apply_quantization_to_conv1d(model):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Apply dynamic quantization to Conv1D layers in the model\n",
    "    quantized_model = quantize_dynamic(\n",
    "        model,  # The model to quantize\n",
    "        dtype=torch.qint8  # Use int8 for more space reduction\n",
    "    )\n",
    "\n",
    "\n",
    "    return quantized_model\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91188d38314db5f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "quantized_model = apply_quantization_to_conv1d(model.model)\n",
    "for name, param in quantized_model.named_parameters():\n",
    "    param.dtype = torch.qint8\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ae7e17640a5363a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(quantized_model.state_dict(), 'quantized_model.pt')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d793dc8d20b914d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_tensor(quantized_model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d29c3519c6aafa46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c58e8c372dd83abc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.quantization import quantize_dynamic, default_dynamic_qconfig\n",
    "from transformers.pytorch_utils import Conv1D\n",
    "\n",
    "# Define a custom quantization configuration\n",
    "qconfig_spec = {\n",
    "    nn.Linear: default_dynamic_qconfig,\n",
    "    Conv1D: default_dynamic_qconfig,  # Add Conv1D for GPT2\n",
    "}\n",
    "\n",
    "# Define a custom mapping for Conv1D to itself (dynamic quantization assumes the same layer works)\n",
    "from torch.quantization.quantization_mappings import get_default_dynamic_quant_module_mappings\n",
    "custom_mapping = get_default_dynamic_quant_module_mappings()\n",
    "custom_mapping[Conv1D] = Conv1D\n",
    "\n",
    "# Apply dynamic quantization\n",
    "def quantize_gpt2_model(model):\n",
    "    model = quantize_dynamic(\n",
    "        model,\n",
    "        qconfig_spec=qconfig_spec,\n",
    "        mapping=custom_mapping,\n",
    "        dtype=torch.qint8,  # Specify the desired dtype\n",
    "        inplace=False  # Create a quantized copy\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "quantized_model = quantize_gpt2_model(model.model)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1d7f09e91c0945d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sparse_state_dict = torch.load(\"/Users/sebastian/PycharmProjects/model-compression/models/rtf_small/id000017342868701547638784/rtf_model.pt\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c8b27f7a53d19fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c3cd937dc942e209"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "603413fd1bafa07f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
